# -*- coding: utf-8 -*-
"""IDX_Partners_VIX_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NCUCJxi6fiSO0jich6i-vCtq46yka0er

#**Machine Learning for Credit Risk Analysis**

### Import Library
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

import warnings
warnings.filterwarnings('ignore')

"""### Load Dataset"""

df = pd.read_csv('loan_data_2007_2014.csv')

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 75)

"""### Sneak Peak Data"""

#Looking at the first 5 rows of the dataset
df.head()

#Looking at the last 5 rows of the dataset
df.tail()

#How many rows and columns in the dataset?
df.shape

#General information of the dataset
df.info()

"""### Handling Missing Values"""

#Checking for missing values
df.isnull().sum()

#Deleting unused columns
dropped = ['revol_bal', 'id', 'member_id', 'Unnamed: 0', 'funded_amnt', 'funded_amnt_inv', 'url', 'desc', 'title', 'addr_state', 'zip_code', 'next_pymnt_d', 'last_pymnt_d', 'mths_since_last_delinq', 'mths_since_last_record', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d', 'mths_since_last_major_derog', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'out_prncp', 'out_prncp_inv', 'total_rev_hi_lim']

df.drop(columns = dropped, axis=1, inplace=True)

#Deleting all columns with null value above 90%
df = df.loc[:, df.isnull().mean() < .9]

df.isnull().sum()

"""## Data Preprocessing

###Loan Status
"""

df.loan_status.value_counts()

good_loan = ['Current', 'Fully Paid', 'In Grace Period', 'Does not meet the credit policy. Status:Fully Paid', 'Late (16-30 days)']
df['loan_stats'] = np.where(df['loan_status'].isin(good_loan), 0, 1)

df.drop('loan_status', axis=1, inplace=True)

"""###Categorical Data"""

df['policy_code'].unique()

#Policy code only has 1 unique value
df.drop('policy_code', axis=1, inplace=True)

#Application type only has 1 unique value
df['application_type'].unique()

df.drop('application_type', axis=1, inplace=True)

df['emp_length'].unique()

#Cleaning emp_length values
df['emp_length'] = df['emp_length'].str.replace('\+ years', '')
df['emp_length'] = df['emp_length'].str.replace('< 1 year', str(0))
df['emp_length'] = df['emp_length'].str.replace(' years', '')
df['emp_length'] = df['emp_length'].str.replace(' year', '')
df['emp_length'] = df['emp_length'].astype(float)

#Converting emp_title values to uppercase
df['emp_title'] = df['emp_title'].str.upper()

#Cleaning term values
df['term'] = df['term'].str.replace(' months', '')
df['term'] = df['term'].astype(float)

#Looking at values in other columns
cat = df.select_dtypes (include= ['object'])

for col in cat.columns.tolist():
    print(df[col].value_counts()[:20])
    print('\n')

#Dominated by a single value
df.drop('pymnt_plan', axis=1, inplace=True)

"""###Date

####earliest_cr_line
"""

df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'], format='%b-%y')
df['earliest_cr_line'].head()

df['mths_since_earliest_cr_line'] = round(pd.to_numeric((pd.to_datetime('2016-12-31') - df['earliest_cr_line']) / np.timedelta64(1, 'M')))
df['mths_since_earliest_cr_line'].head()

df['mths_since_earliest_cr_line'].describe()

df[df['mths_since_earliest_cr_line']<0][['earliest_cr_line', 'mths_since_earliest_cr_line']].head()

df.loc[df['mths_since_earliest_cr_line']<0, 'mths_since_earliest_cr_line'] = df['mths_since_earliest_cr_line'].max()

df.drop(['earliest_cr_line'], axis=1, inplace=True)

"""####issue_d"""

df['issue_d'] = pd.to_datetime(df['issue_d'], format='%b-%y')
df['issue_d'].head()

df['mths_since_issue_d'] = round(pd.to_numeric((pd.to_datetime('2016-12-31') - df['issue_d']) / np.timedelta64(1, 'M')))
df['mths_since_issue_d'].head()

df['mths_since_issue_d'].describe()

df.drop(['issue_d'], axis=1, inplace=True)

df.head()

"""## Exploratory Data Analysis"""

#Describing the dataset
df.describe()

data_plot  = df['loan_stats'].value_counts().to_list()
label_plot = df['loan_stats'].value_counts().index.to_list()

title = 'Loan Status (0 = Good, 1 = Bad)'

plot       = sns.barplot(x = label_plot, y = data_plot, palette = 'CMRmap')
plot_title = plt.title(title)

plt.show()

df['loan_stats'].value_counts()

data_plot  = df['emp_title'].value_counts()[:20].to_list()
label_plot = df['emp_title'].value_counts()[:20].index.to_list()

title = 'Top 20 Professions'

plot       = sns.barplot(x = label_plot, y = data_plot, palette = 'CMRmap')
plot_title = plt.title(title)
plt.show()

df['emp_title'].value_counts()[:20]

data_plot  = df['emp_length'].value_counts().to_list()
label_plot = df['emp_length'].value_counts().index.to_list()

title = 'Employment Length'

plot       = sns.barplot(x = label_plot, y = data_plot, palette = 'CMRmap')
plot_title = plt.title(title)

plt.show()

df['emp_length'].value_counts()

#Correlations between features
matrix = df.corr().round(2)
plt.figure(figsize=(16,16))
sns.heatmap(matrix, annot=True, vmax=1, vmin=-1, center=0, cmap='coolwarm')
title = 'Feature Correlations'
plt.show()

cat = df.select_dtypes (include= ['object'])

for col in cat.columns.tolist():
    print(df[col].value_counts())
    print('\n')

#Risk percentage of bad credit
def risk_percentage(x):
    ratio = (df.groupby(x)['loan_stats']
         .value_counts(normalize=True)
         .mul(100)
         .rename('risk (%)')
         .reset_index())

    sns.lineplot(data=ratio[ratio['loan_stats'] == 1], x=x, y='risk (%)')
    plt.title(x)
    plt.show()

columns = ['term', 'initial_list_status', 'verification_status', 'home_ownership', 'acc_now_delinq','grade', 'sub_grade', 'inq_last_6mths', 'collections_12_mths_ex_med', 'emp_length', 'mths_since_issue_d', 'mths_since_earliest_cr_line']
for cols in columns:
    risk_percentage(cols)

df.groupby(by = 'loan_stats').mean()

pd.crosstab(index=df['loan_stats'], columns=df['grade'])

pd.crosstab(index=df['loan_stats'], columns=df['sub_grade'])

pd.crosstab(index=df['loan_stats'], columns=df['mths_since_issue_d'])

pd.crosstab(index=df['loan_stats'], columns=df['mths_since_earliest_cr_line'])

pd.crosstab(index=df['loan_stats'], columns=df['home_ownership'])

pd.crosstab(index=df['loan_stats'], columns=df['verification_status'])

pd.pivot_table(df, values='loan_amnt', index='loan_stats', columns='grade', aggfunc=np.mean)

pd.pivot_table(df, values='annual_inc', index='loan_stats', columns='grade', aggfunc=np.mean)

pd.pivot_table(df, values='loan_amnt', index='loan_stats', columns='home_ownership', aggfunc=np.mean)

"""##Missing Data Imputation"""

df.isnull().sum()

#Filling missing data
df['annual_inc'].fillna(df['annual_inc'].mean(), inplace=True)
df['mths_since_earliest_cr_line'].fillna(0, inplace=True)
df['acc_now_delinq'].fillna(0, inplace=True)
df['total_acc'].fillna(0, inplace=True)
df['pub_rec'].fillna(0, inplace=True)
df['open_acc'].fillna(0, inplace=True)
df['inq_last_6mths'].fillna(0, inplace=True)
df['delinq_2yrs'].fillna(0, inplace=True)
df['collections_12_mths_ex_med'].fillna(0, inplace=True)
df['revol_util'].fillna(0, inplace=True)
df['tot_cur_bal'].fillna(0, inplace=True)
df['tot_coll_amt'].fillna(0, inplace=True)

df.head()

df['open_acc'] = df['open_acc'].astype(int)
df['pub_rec'] = df['pub_rec'].astype(int)
df['total_acc'] = df['total_acc'].astype(int)
df['acc_now_delinq'] = df['acc_now_delinq'].astype(int)

df.info()

#Categorical data
cat = df.select_dtypes (include= ['object'])
cat

#Removing unnecessary data
dropped = ['emp_length', 'emp_title', 'grade', 'mths_since_issue_d']
df.drop(columns = dropped, axis=1, inplace=True)

"""Dropped values:
* emp_title and emp_length - not relevant
* grade - in this model, sub_grade is used instead because it is more specific
* mths_since_issue_d - this data is not known before the credit is approved
"""

#Labeling categorical data
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

class MultiColumnLabelEncoder:
    def __init__(self,columns = None):
        self.columns = columns # array of column names to encode

    def fit(self,X,y=None):
        return self # not relevant here

    def transform(self,x):
        '''
        Transforms columns of X specified in self.columns using
        LabelEncoder(). If no columns specified, transforms all
        columns in X.
        '''
        output = x.copy()
        if self.columns is not None:
            for col in self.columns:
                output[col] = LabelEncoder().fit_transform(output[col])
        else:
            for colname,col in output.iteritems():
                output[colname] = LabelEncoder().fit_transform(col)
        return output

    def fit_transform(self,x,y=None):
        return self.fit(x,y).transform(x)

df = MultiColumnLabelEncoder(columns = ['sub_grade', 'home_ownership', 'verification_status',	'purpose', 'initial_list_status']).fit_transform(df)

"""## Splitting the dataset into the Training set and Test set"""

#Defining x and y
x = df.drop(columns=['loan_stats'], axis = 1)
y = df['loan_stats']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)

x_train.shape, x_test.shape

"""##Balancing data

The data is unbalanced, so we need to balance it first by oversampling the minority.
"""

from imblearn.over_sampling import SMOTE

SMOTE = SMOTE()
x_train, y_train = SMOTE.fit_resample(x_train, y_train)

"""## Modelling

### Random Forest
"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(max_depth=5)

#Training the model
rf.fit(x_train, y_train)

#Predict testing set
y_pred = rf.predict(x_test)

print('Training-set accuracy score:', rf.score(x_train, y_train))
print('Test-set accuracy score:', rf.score(x_test, y_test))

plt.figure(figsize=(6,6))
sns.heatmap(confusion_matrix(y_test,y_pred), annot=True, fmt='d', cmap='Purples')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for Random Forest')
plt.show()

#Check model performance using classification_report
print(classification_report(y_test, y_pred))

#Check model performance using auc score
roc_auc_score(y_test, y_pred)*100